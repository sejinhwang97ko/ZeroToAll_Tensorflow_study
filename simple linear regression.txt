Linear Regression: 데이터를 잘 대변하는 직선의 방정식(기울기와 y절편을 가지고 있음)을 찾는 것
Hypothesis함수(우리의 모델): H(x) = Wx + b
H(x) - y 를 cost or loss or error 라고 함
어떤 부분은 양수로 나타나고 어떤 부분은 음수로 나타나기 때문에
error 값을 제곱을 사용
제곱해서 평균을 내는 것을 비용함수로 많이 사용함.
비용함수가 제일 작은 것을 찾는 것(W를): 우리의 목적 (= 학습(learning)) <- 이런 알고리즘이 Gradient descent